{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bb5b92dd",
   "metadata": {},
   "source": [
    "# Reproduce the results presented in \"CRISPR-HAWK: Haplotype- and Variant-Aware Guide Design Toolkit for CRISPR-Cas\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e48317ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import subprocess\n",
    "import random\n",
    "import pysam\n",
    "import os\n",
    "\n",
    "# from tqdm import tqdm\n",
    "from time import time\n",
    "from matplotlib.lines import Line2D\n",
    "from matplotlib.font_manager import FontProperties\n",
    "from matplotlib.colors import LinearSegmentedColormap"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5b930a4",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "CRISPR-HAWK is a comprehensive and scalable framework for designing guide RNAs \n",
    "(gRNAs) and evaluating the impact of genetic variation on CRISPR-Cas on-target \n",
    "activity. Developed as an offline, user-friendly command-line tool, CRISPR-HAWK \n",
    "integrates large-scale human variation datasets, including the 1000 Genomes Project, \n",
    "the Human Genome Diversity Project (HGDP), and gnomAD, with orthogonal \n",
    "genomic annotations to systematically prioritize gRNAs targeting regions of interest.\n",
    "\n",
    "The framework is Cas-agnostic and supports a broad range of nucleases, such as \n",
    "Cas9, SaCas9, and Cpf1 (Cas12a), while also allowing full customization of PAM \n",
    "sequences and guide lengths. This flexibility ensures compatibility with emerging \n",
    "CRISPR technologies and enables users to tailor gRNA design to specific experimental \n",
    "needs.\n",
    "\n",
    "CRISPR-HAWK incorporates both single-nucleotide variants (SNVs) and small \n",
    "insertions and deletions (indels), and it natively handles individual- and \n",
    "population-specific haplotypes. This makes it particularly suitable for personalized \n",
    "genome editing as well as population-scale analyses. The workflow, from variant-aware \n",
    "preprocessing to gRNA discovery, is fully automated, generating ranked candidate \n",
    "gRNAs, annotated target sequences, and publication-ready visualizations.\n",
    "\n",
    "Thanks to its modular architecture, CRISPR-HAWK can be seamlessly integrated with \n",
    "downstream tools such as CRISPRme or CRISPRitz for comprehensive off-target prediction \n",
    "and follow-up analysis of prioritized guides.\n",
    "\n",
    "This notebook reproduce the results presented in |||**add paper-link**|||."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c26072b6",
   "metadata": {},
   "source": [
    "## Download data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55f51b00",
   "metadata": {},
   "source": [
    "### Downloading Genetic Variation Datasets (1000 Genomes, HGDP, gnomAD)\n",
    "\n",
    "CRISPR-HAWK supports large-scale genetic diversity analyses by integrating variation \n",
    "from several major population genomics resources. This section provides instructions \n",
    "for downloading the VCF files required to reproduce the results presented in the paper.\n",
    "\n",
    "**Overview of Supported Datasets**\n",
    "\n",
    "- 1000 Genomes Project (Phase 3)\n",
    "  <br>2,504 individuals from 26 global populations; whole-genome sequencing at ~30×.\n",
    "\n",
    "- Human Genome Diversity Project (HGDP)\n",
    "  <br>929 individuals from globally diverse populations; high-coverage WGS.\n",
    "\n",
    "- gnomAD (v4.1)\n",
    "  <br>Population-scale aggregated variation from ~76,000 genomes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07b4b94a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define datasets urls\n",
    "url_hgdp = (\n",
    "    \"https://ngs.sanger.ac.uk/production/hgdp/hgdp_wgs.20190516/\" \n",
    "    \"hgdp_wgs.20190516.full.chr{}.vcf.gz\"\n",
    ")\n",
    "url_1kgp = (\n",
    "    \"ftp://ftp.1000genomes.ebi.ac.uk/vol1/ftp/data_collections/\"\n",
    "    \"1000_genomes_project/release/20190312_biallelic_SNV_and_INDEL/\" \n",
    "    \"ALL.chr{}.shapeit2_integrated_snvindels_v2a_27022019.GRCh38.phased.vcf.gz\"\n",
    ")\n",
    "url_gnomad = (\n",
    "    \"https://storage.googleapis.com/gcp-public-data--gnomad/release/4.1/vcf/\" \n",
    "    \"genomes/gnomad.genomes.v4.1.sites.chr{}.vcf.bgz\"\n",
    ")\n",
    "variants = {\"HGDP\": url_hgdp, \"1000G\": url_1kgp, \"GNOMAD\": url_gnomad}\n",
    "\n",
    "# define chromosomes\n",
    "chroms = [2, 3, 7, 11]\n",
    "\n",
    "# download files\n",
    "for dataset, url in variants.items():\n",
    "    vcfdir = os.path.join(\"vcf\", dataset)\n",
    "    if dataset == \"GNOMAD\":\n",
    "        vcfdir = os.path.join(vcfdir, \"raw\")\n",
    "    os.makedirs(vcfdir, exist_ok=True)  # create dataset folder \n",
    "    for c in chroms:        \n",
    "        # download VCF and index\n",
    "        ! wget -P {vcfdir} {url.format(c)}\n",
    "        ! wget -P {vcfdir} {url.format(c)}.tbi"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6f2b59c",
   "metadata": {},
   "source": [
    "Unlike the 1000 Genomes and HGDP callsets, the gnomAD VCFs contain allele frequency \n",
    "information only and do not provide individual-level genotype data. Since \n",
    "CRISPR-HAWK requires genotypes to reconstruct haplotypes and perform variant-aware \n",
    "gRNA discovery, gnomAD VCFs must first be converted into a compatible, pseudo-genotyped \n",
    "format. To enable this, we use the CRISPR-HAWK VCF converter, which generates a \n",
    "CRISPR-HAWK–ready VCF while preserving population-level allele distributions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcd930da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check gnomad folder exists\n",
    "gnomad_dir = \"vcf/GNOMAD\"\n",
    "gnomad_raw_dir = os.path.join(gnomad_dir, \"raw\")\n",
    "assert os.path.isdir(gnomad_raw_dir)\n",
    "\n",
    "# create converted VCFs folder\n",
    "gnomad_gt_dir = os.path.join(gnomad_dir, \"genotype\")\n",
    "os.makedirs(gnomad_gt_dir, exist_ok=True)\n",
    "\n",
    "# convert gnoamd VCFs using crisprhawk (it may take some time)\n",
    "! crisprhawk convert-gnomad-vcf -d {gnomad_raw_dir} -o {gnomad_gt_dir}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a6a36a1",
   "metadata": {},
   "source": [
    "### Downloading the hg38 Reference Genome\n",
    "\n",
    "CRISPR-HAWK requires a reference genome to extract genomic contexts, evaluate \n",
    "variant-aware target sequences, and correctly map gRNA target sites. In this \n",
    "section, we download the primary assembly FASTA filesfrom the Genome Reference \n",
    "Consortium–maintained repositories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34d9e1bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define chromosomes\n",
    "chroms = [2, 3, 7, 11]\n",
    "\n",
    "# create genome folder\n",
    "genome_dir = \"genome\"\n",
    "os.makedirs(genome_dir, exist_ok=True)\n",
    "\n",
    "# define genome url\n",
    "url_ucsc = (\n",
    "    \"https://hgdownload.soe.ucsc.edu/goldenpath/hg38/chromosomes/chr{}.fa.gz\"\n",
    ")\n",
    "\n",
    "# Download and unzip FASTA file for each chromosome\n",
    "for c in chroms:\n",
    "    print(f\"Downloading FASTA for chromosome {c}\")\n",
    "    ! wget -nc -P {genome_dir} {url_ucsc.format(c)}\n",
    "    ! gunzip -f {genome_dir}/chr{c}.fa.gz"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5f39fe4",
   "metadata": {},
   "source": [
    "### Creating BED Files for the Analyzed Regions\n",
    "\n",
    "CRISPR-HAWK requires BED files to define the genomic intervals where gRNA discovery \n",
    "and variant-aware analysis will be performed. Each BED file specifies one or more \n",
    "regions of interest in the standard 3-column BED format:\n",
    "```\n",
    "chrom   start   end\n",
    "```\n",
    "\n",
    "Coordinates must reference the hg38 genome assembly (or whichever reference you \n",
    "downloaded in the previous step)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b476416",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create region folder\n",
    "regions_dir = \"regions\"\n",
    "os.makedirs(regions_dir, exist_ok=True)\n",
    "\n",
    "# define regions\n",
    "regions = {\n",
    "    \"BCL11A\": [\"chr2\", 60495215, 60496479],\n",
    "    \"EMX1\":   [\"chr2\", 72932853, 72934853],\n",
    "    \"CCR5_1\":   [\"chr3\", 46372138, 46374138],\n",
    "    \"CCR5_2\":   [\"chr3\", 46372162, 46374162],\n",
    "    \"TRBC1\":  [\"chr7\", 142791004, 142793004],\n",
    "    \"TRBC2\":  [\"chr7\", 142800351, 142802350],\n",
    "    \"HBB_1\":    [\"chr11\", 5225803, 5227803],\n",
    "    \"HBB_2\":    [\"chr11\", 5225967, 5227967],\n",
    "    \"HBG2_CAS9\":   [\"chr11\", 5252879, 5256879],\n",
    "    \"HBG1_CAS9\":   [\"chr11\", 5248955, 5250955],\n",
    "    \"HBG2_CPF1\":   [\"chr11\", 5253874, 5255874],\n",
    "    \"HBG1_CPF1\":   [\"chr11\", 5248950, 5250950],\n",
    "    \"FANCF\":  [\"chr11\", 22624785, 22626785],\n",
    "}\n",
    "\n",
    "# create bed files \n",
    "for gene, (chrom, start, end) in regions.items():\n",
    "    bed_fname = os.path.join(regions_dir, f\"{gene}.bed\")\n",
    "    with open(bed_fname, mode=\"w\") as f:\n",
    "        f.write(f\"{chrom}\\t{start}\\t{end}\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4ef53cb",
   "metadata": {},
   "source": [
    "## Variant-Aware gRNA Retrieval on Defined Regions\n",
    "\n",
    "With the reference genome, variant datasets, and BED files prepared, CRISPR-HAWK\n",
    "can now retrieve all candidate gRNAs within the specified regions while accounting\n",
    "for genetic variation across populations and individuals. This step is central to \n",
    "CRISPR-HAWK’s design philosophy: guide discovery must be variant-aware, ensuring \n",
    "that both reference and haplotype-specific target sequences are evaluated.\n",
    "\n",
    "**What This Step Does**\n",
    "\n",
    "For each genomic interval listed in the BED file(s), CRISPR-HAWK:\n",
    "\n",
    "- Extracts the reference sequence from hg38.\n",
    "\n",
    "- Applies all relevant variants (SNVs and indels) from the loaded dataset,\n",
    "including 1000G, HGDP, or converted gnomAD, to reconstruct individual, and population-specific haplotypes.\n",
    "\n",
    "- Scans both the reference and haplotype sequences to identify all gRNAs that match the user-defined:\n",
    "\n",
    "    - PAM sequence (e.g., NGG, NAA, TTTV, …)\n",
    "\n",
    "    - guide length\n",
    "\n",
    "    - nuclease type (Cas9, SaCas9, Cpf1/Cas12a, etc.)\n",
    "\n",
    "- Reports each gRNA along with:\n",
    "\n",
    "    - its exact reference and alternative alleles\n",
    "\n",
    "    - per-haplotype presence/absence\n",
    "\n",
    "    - the samples in which the target site is altered\n",
    "\n",
    "    - summary metrics for prioritization\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2587f587",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define target regions\n",
    "targets = [\n",
    "    \"BCL11A\",\n",
    "    \"EMX1\",\n",
    "    \"CCR5_1\",\n",
    "    \"CCR5_2\",\n",
    "    \"TRBC1\",\n",
    "    \"TRBC2\",\n",
    "    \"FANCF\",\n",
    "    \"HBB_1\",\n",
    "    \"HBB_2\",\n",
    "    \"HBG1_CAS9\",\n",
    "    \"HBG2_CAS9\",\n",
    "    \"HBG1_CPF1\",\n",
    "    \"HBG1_CPF1\",\n",
    "]\n",
    "\n",
    "# define genetic variants datasets\n",
    "datasets = [\"1000G\", \"HGDP\", \"gnomAD\"]\n",
    "\n",
    "# define pams\n",
    "pams = [\"NGG\", \"TTTV\"] # Cas9, Cas12\n",
    "guide_lens = [20, 23]\n",
    "thread = 16\n",
    "\n",
    "# define folders \n",
    "genome_dir = \"genome\"\n",
    "variants_dir = \"vcf\"\n",
    "regions_dir = \"regions\"\n",
    "results_dir = \"results\"\n",
    "\n",
    "# create results folder\n",
    "os.makedirs(results_dir, exist_ok=True)\n",
    "\n",
    "# run guide design with crisprhawk\n",
    "for dataset in datasets:\n",
    "    vcfdir = os.path.join(variants_dir, dataset)\n",
    "    if dataset == \"gnomAD\":\n",
    "        vcfdir = os.path.join(vcfdir, \"genotype\")\n",
    "    results_dataset = os.path.join(results_dir, dataset)\n",
    "    os.makedirs(results_dataset, exist_ok=True)  # e.g. results/1000G \n",
    "    for target in targets:\n",
    "        target_region = os.path.join(regions_dir, f\"{target}.bed\")\n",
    "        pams_ = pams if target.endswith(\"_CPF1\") else pams[:1]\n",
    "        results_target = os.path.join(results_dataset, target)  # e.g. results/1000G/BCL11A\n",
    "        for pam in pams_:\n",
    "            guidelen = 20 if pam == \"NGG\" else 23\n",
    "            crisprhawk_cmd = (\n",
    "                \"crisprhawk search \" \n",
    "                f\"-f {genome_dir} \" \n",
    "                f\"-r {target_region} \"\n",
    "                f\"-v {vcfdir} \"\n",
    "                f\"-p {pam} \"\n",
    "                f\"-g {guidelen} \"\n",
    "                f\"--haplotype-table \"\n",
    "                \"--threads 16 \"\n",
    "                f\"-o {results_target}\"\n",
    "                \"--verbosity 0\"\n",
    "            )\n",
    "            print(f\"Running search on {dataset} for target {target}\")\n",
    "            subprocess.call(crisprhawk_cmd, shell=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf0583cf",
   "metadata": {},
   "source": [
    "## Results Analysis and Visualization\n",
    "\n",
    "In this section, we analyze and visualize the impact of genetic variation on gRNA \n",
    "design and activity across a curated set of clinically and experimentally relevant \n",
    "CRISPR targets. The analysis focuses on how population-level and individual-specific \n",
    "variants affect both gRNA sequence composition and expected on-target efficiency, \n",
    "highlighting differences between reference-designed guides and their alternative, \n",
    "haplotype-derived counterparts.\n",
    "\n",
    "For each target region, we first quantify how genetic variation alters the landscape \n",
    "of candidate gRNAs. Specifically, we classify retrieved guides into four categories \n",
    "and summarize them using pie charts:\n",
    "- gRNAs matching the reference sequence\n",
    "- gRNAs with variants in the spacer region\n",
    "- gRNAs with variants affecting only the PAM\n",
    "- gRNAs with variants in both the spacer and the PAM\n",
    "\n",
    "This provides an immediate overview of how frequently genetic variants modify \n",
    "targetable sequences across different loci. \n",
    "\n",
    "Next, we assess the functional consequences of these sequence differences. Using \n",
    "dot plots, we compare:\n",
    "- The predicted on-target efficiency of reference gRNAs versus their alternative \n",
    "  versions found on variant-defined haplotypes\n",
    "- The residual on-target activity of reference gRNAs when applied to alternative \n",
    "  haplotypes carrying sequence mismatches\n",
    "\n",
    "These analyses capture both gain and loss of activity induced by genetic variation \n",
    "and enable a fine-grained comparison between reference and variant-aware gRNA designs.\n",
    "\n",
    "All analyses are performed independently for the following target regions:\n",
    "- BCL11A +58 Erythroid enhancer\n",
    "- EMX1\n",
    "- CCR5 (two independent target sites)\n",
    "- TRBC1\n",
    "- TRBC2\n",
    "- FANCF\n",
    "- HBB (two independent target sites)\n",
    "- HBG1 and HBG2 (Cas9)\n",
    "- HBG1 (Cpf1/Cas12a)\n",
    "\n",
    "For Cpf1-based targets, residual on-target activity is not evaluated, as the \n",
    "analysis is specific to Cas9-mediated spacer–PAM interactions.\n",
    "\n",
    "The analyses integrate variation from 1000 Genomes, HGDP, and gnomAD datasets. \n",
    "In particular, for the sg1617 guide targeting the BCL11A erythroid enhancer, we \n",
    "perform an in-depth follow-up analysis: for each alternative gRNA sequence generated \n",
    "by gnomAD variants, we run CRISPRme (using 1000G + HGDP genetic variants) to \n",
    "evaluate guide specificity genome-wide. This allows us to compare how genetic \n",
    "variation simultaneously affects on-target activity and off-target risk, \n",
    "providing a comprehensive assessment of guide performance in a population-aware \n",
    "context."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "323891a7",
   "metadata": {},
   "source": [
    "### Assigning Sample Support to Candidate gRNAs\n",
    "\n",
    "As a first step in the results analysis, we quantify how widely each candidate \n",
    "gRNA is supported across individuals in each variant datasets. For every gRNA \n",
    "retrieved in the previous step, we compute the number of samples carrying the \n",
    "exact gRNA sequence in their reconstructed haplotypes.\n",
    "\n",
    "These sample support counts form the basis for all downstream analyses in this \n",
    "section, including the evaluation of efficiency differences between reference \n",
    "and alternative guides, and reference on-target residual activity on alternative\n",
    "haplotypes. \n",
    "\n",
    "For datasets providing individual-level genotypes (e.g., 1000 Genomes and HGDP), \n",
    "sample support is directly derived from haplotype reconstruction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67e621c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "SAMPLESNUM = {\"1000G\": 2504, \"HGDP\": 929, \"gnomAD\": 76215}\n",
    "\n",
    "def _compute_id(chrom, start, stop, strand):\n",
    "    return f\"{chrom}_{start}_{stop}_{strand}\"\n",
    "\n",
    "def compute_samples_num(df, samplesnum):\n",
    "    assert \"samples\" in df.columns.tolist()\n",
    "    # count samples carrying alternative grnas\n",
    "    df[\"n_samples\"] = df[\"samples\"].apply(\n",
    "        lambda x: len(str(x).split(\",\")) if pd.notna(x) and x!= \"REF\" else None\n",
    "    )  \n",
    "    # compute guide id for each grna\n",
    "    df[\"guide_id\"] = df.apply(\n",
    "        lambda x: _compute_id(x[\"chr\"], x[\"start\"], x[\"stop\"], x[\"strand\"]), axis=1\n",
    "    )\n",
    "    # sum samples carrying alternative guides\n",
    "    sum_alternative = df[df[\"samples\"] != \"REF\"].groupby(\"guide_id\")[\"n_samples\"].sum()\n",
    "    # retrieve number of samples for reference grnas\n",
    "    refmask = df[\"samples\"] == \"REF\"\n",
    "    df.loc[refmask, \"n_samples\"] = samplesnum - df.loc[refmask, \"guide_id\"].map(sum_alternative).fillna(0)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73ef0f2e",
   "metadata": {},
   "source": [
    "For gnomAD-based analyses, individual genotypes are not directly available. In \n",
    "this case, CRISPR-HAWK reports the number of populations carrying each gRNA rather\n",
    "than explicit sample counts. To enable downstream analyses requiring sample-level \n",
    "support, we post-process CRISPR-HAWK reports by annotating them with gnomAD \n",
    "carrier counts using pysam. This procedure estimates the number of carriers for\n",
    "each variant allele underlying a gRNA and propagates this information to the \n",
    "guide level.\n",
    "\n",
    "These sample support estimates are then used consistently with the other datasets \n",
    "to classify gRNAs and to perform comparative analyses across reference and \n",
    "variant-derived guides."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f87bc4fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# gnomad-only post-processing (NB: may require hours to run)\n",
    "def _retrieve_position(variant_id):\n",
    "    return int(variant_id.split(\"-\")[1])\n",
    "\n",
    "def extract_variant_positions(df):\n",
    "    # retrieve position of each variant\n",
    "    variant_ids = df[\"variant_id\"].dropna().tolist()\n",
    "    return {_retrieve_position(v) for vs in variant_ids for v in vs.split(\",\")}\n",
    "\n",
    "def get_relevant_variants(vcf_fname, chrom, positions):\n",
    "    print(f\"Scanning VCF for {len(positions)} positions on {chrom}\")\n",
    "    vcf = pysam.VariantFile(vcf_fname)  # load vcf\n",
    "    variants, matches = [], set()\n",
    "\n",
    "    # requires bgzipped vcf with tbi index\n",
    "    for r in tqdm(vcf.fetch(chrom), desc=\"Scanning VCF\", unit=\"variants\"):\n",
    "        if r.pos not in positions:\n",
    "            continue\n",
    "    \n",
    "        ac = r.info.get(\"AC\")  # read allele count\n",
    "        if ac is None:\n",
    "            continue\n",
    "\n",
    "        nhomalt = r.info.get(\"nhomalt\", 0)  # count number of homozygous for alternative\n",
    "\n",
    "        # iterate on each alternative allele\n",
    "        for i, alt in enumerate(r.alts):\n",
    "            # scalar vs per-allele fields for AC and nhomalt\n",
    "            if isinstance(ac, (list, tuple)):\n",
    "                ac_ = ac[i] if i < len(ac) else None\n",
    "            else:\n",
    "                ac_ = ac\n",
    "            if ac_ is None:\n",
    "                continue\n",
    "\n",
    "            if isinstance(nhomalt, (list, tuple)):\n",
    "                nhomalt_ = nhomalt[i] if i < len(nhomalt) else 0\n",
    "            else:\n",
    "                nhomalt_ = nhomalt\n",
    "\n",
    "            # compute number of heterozygous samples\n",
    "            n_het = ac_ - 2 * nhomalt_\n",
    "            n_total = nhomalt_ + n_het\n",
    "\n",
    "            # add variants and matched position\n",
    "            variant_id = f\"{r.chrom}-{r.pos}-{r.ref}/{alt}\"\n",
    "            variants.append(\n",
    "                {\n",
    "                    \"variant_id\": variant_id,\n",
    "                    \"chrom\": r.chrom,\n",
    "                    \"pos\": r.pos,\n",
    "                    \"ref\": r.ref,\n",
    "                    \"alt\": alt,\n",
    "                    \"AC\": ac_,\n",
    "                    \"n_hom\": nhomalt_,\n",
    "                    \"n_het\": n_het,\n",
    "                    \"n_samples\": n_total\n",
    "                }\n",
    "            )\n",
    "            matches.add(r.pos)\n",
    "    print(f\"Matched {len(matches)} of {len(positions)} positions\")\n",
    "    return pd.DataFrame(variants)\n",
    "\n",
    "\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "data-analysis-ngs",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
