{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bb5b92dd",
   "metadata": {},
   "source": [
    "# Reproduce the results presented in \"CRISPR-HAWK: Haplotype- and Variant-Aware Guide Design Toolkit for CRISPR-Cas\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e48317ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.colors import LinearSegmentedColormap\n",
    "from matplotlib.lines import Line2D\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import warnings\n",
    "import random\n",
    "import os\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5b930a4",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "CRISPR-HAWK is a comprehensive and scalable framework for designing guide RNAs \n",
    "(gRNAs) and evaluating the impact of genetic variation on CRISPR-Cas on-target \n",
    "activity. Developed as an offline, user-friendly command-line tool, CRISPR-HAWK \n",
    "integrates large-scale human variation datasets, including the 1000 Genomes Project, \n",
    "the Human Genome Diversity Project (HGDP), and gnomAD, with orthogonal \n",
    "genomic annotations to systematically prioritize gRNAs targeting regions of interest.\n",
    "\n",
    "The framework is Cas-agnostic and supports a broad range of nucleases, such as \n",
    "Cas9, SaCas9, and Cpf1 (Cas12a), while also allowing full customization of PAM \n",
    "sequences and guide lengths. This flexibility ensures compatibility with emerging \n",
    "CRISPR technologies and enables users to tailor gRNA design to specific experimental \n",
    "needs.\n",
    "\n",
    "CRISPR-HAWK incorporates both single-nucleotide variants (SNVs) and small \n",
    "insertions and deletions (indels), and it natively handles individual- and \n",
    "population-specific haplotypes. This makes it particularly suitable for personalized \n",
    "genome editing as well as population-scale analyses. The workflow, from variant-aware \n",
    "preprocessing to gRNA discovery, is fully automated, generating ranked candidate \n",
    "gRNAs, annotated target sequences, and publication-ready visualizations.\n",
    "\n",
    "Thanks to its modular architecture, CRISPR-HAWK can be seamlessly integrated with \n",
    "downstream tools such as CRISPRme or CRISPRitz for comprehensive off-target prediction \n",
    "and follow-up analysis of prioritized guides.\n",
    "\n",
    "This notebook generates the figures presented in |||**add paper-link**|||."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8e689fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define static variables\n",
    "CRISPRHAWKDIR = \"crisprhawk-data\"\n",
    "RESULTSDIR = os.path.join(CRISPRHAWKDIR, \"results_nsamples\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf0583cf",
   "metadata": {},
   "source": [
    "## Results Analysis and Visualization\n",
    "\n",
    "In this section, we analyze and visualize the impact of genetic variation on gRNA \n",
    "design and activity across a curated set of clinically and experimentally relevant \n",
    "CRISPR targets. The analysis focuses on how population-level and individual-specific \n",
    "variants affect both gRNA sequence composition and expected on-target efficiency, \n",
    "highlighting differences between reference-designed guides and their alternative, \n",
    "haplotype-derived counterparts.\n",
    "\n",
    "For each target region, we first quantify how genetic variation alters the landscape \n",
    "of candidate gRNAs. Specifically, we classify retrieved guides into four categories \n",
    "and summarize them using pie charts:\n",
    "- gRNAs matching the reference sequence\n",
    "- gRNAs with variants in the spacer region\n",
    "- gRNAs with variants affecting only the PAM\n",
    "- gRNAs with variants in both the spacer and the PAM\n",
    "\n",
    "This provides an immediate overview of how frequently genetic variants modify \n",
    "targetable sequences across different loci. \n",
    "\n",
    "Next, we assess the functional consequences of these sequence differences. Using \n",
    "dot plots, we compare:\n",
    "- The predicted on-target efficiency of reference gRNAs versus their alternative \n",
    "  versions found on variant-defined haplotypes\n",
    "- The residual on-target activity of reference gRNAs when applied to alternative \n",
    "  haplotypes carrying sequence mismatches\n",
    "\n",
    "These analyses capture both gain and loss of activity induced by genetic variation \n",
    "and enable a fine-grained comparison between reference and variant-aware gRNA designs.\n",
    "\n",
    "All analyses are performed independently for the following target regions:\n",
    "- BCL11A +58 Erythroid enhancer\n",
    "- EMX1\n",
    "- CCR5 (two independent target sites)\n",
    "- TRBC1\n",
    "- TRBC2\n",
    "- FANCF\n",
    "- HBB (two independent target sites)\n",
    "- HBG1 and HBG2 (Cas9)\n",
    "- HBG1 (Cpf1/Cas12a)\n",
    "\n",
    "For Cpf1-based targets, residual on-target activity is not evaluated, as the \n",
    "analysis is specific to Cas9-mediated spacer–PAM interactions.\n",
    "\n",
    "The analyses integrate variation from 1000 Genomes, HGDP, and gnomAD datasets. \n",
    "In particular, for the sg1617 guide targeting the BCL11A erythroid enhancer, we \n",
    "perform an in-depth follow-up analysis: for each alternative gRNA sequence generated \n",
    "by gnomAD variants, we run CRISPRme (using 1000G + HGDP genetic variants) to \n",
    "evaluate guide specificity genome-wide. This allows us to compare how genetic \n",
    "variation simultaneously affects on-target activity and off-target risk, \n",
    "providing a comprehensive assessment of guide performance in a population-aware \n",
    "context."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b689fd4c",
   "metadata": {},
   "source": [
    "In the following cell, we retrieve the candidate gRNAs retrieved on BCL11A +58 \n",
    "Eythroid enhnacer found by CRISPR-HAWK. Each guide has been processed to \n",
    "retrieve the number of samples in each dataset, carrying that gRNA alternative."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb97ff43",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load BCL11A reports\n",
    "report_fname = \"crisprhawk_guides__chr2_60495215_60496479_NGG_20_nsamples.tsv\"\n",
    "\n",
    "bcl11a_1000G = pd.read_csv(\n",
    "    os.path.join(RESULTSDIR, f\"CAS9/1000G/{report_fname}\"), sep=\"\\t\"\n",
    ")\n",
    "bcl11a_HGDP = pd.read_csv(\n",
    "    os.path.join(RESULTSDIR, f\"CAS9/HGDP/{report_fname}\"), sep=\"\\t\"\n",
    ")\n",
    "bcl11a_GNOMAD = pd.read_csv(\n",
    "    os.path.join(RESULTSDIR, f\"CAS9/GNOMAD/{report_fname}\"), sep=\"\\t\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b092ab5",
   "metadata": {},
   "source": [
    "In the following cell, we retrieve the candidate gRNAs retrieved on HBG1 region\n",
    "found by CRISPR-HAWK. Each guide has been processed to retrieve the number of\n",
    "samples in each dataset, carrying that gRNA alternative."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb2963a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load HBG1 reports\n",
    "report_fname = \"crisprhawk_guides__chr11_5248950_5250050_TTTV_23_nsamples.tsv\"\n",
    "\n",
    "hbg1_1000G = pd.read_csv(\n",
    "    os.path.join(RESULTSDIR, f\"CPF1/1000G/{report_fname}\"), sep=\"\\t\"\n",
    ")\n",
    "hbg1_HGDP = pd.read_csv(os.path.join(RESULTSDIR, f\"CPF1/HGDP/{report_fname}\"), sep=\"\\t\")\n",
    "hbg1_GNOMAD = pd.read_csv(\n",
    "    os.path.join(RESULTSDIR, f\"CPF1/GNOMAD/{report_fname}\"), sep=\"\\t\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c559bcd0",
   "metadata": {},
   "source": [
    "In the following cell, we retrieve the candidate gRNAs retrieved on HBG2 region\n",
    "found by CRISPR-HAWK. Each guide has been processed to retrieve the number of\n",
    "samples in each dataset, carrying that gRNA alternative."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f6b66fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load HBG2 reports\n",
    "report_fname = \"crisprhawk_guides__chr11_5253874_5255874_TTTV_23_nsamples.tsv\"\n",
    "\n",
    "hbg2_1000G = pd.read_csv(\n",
    "    os.path.join(RESULTSDIR, f\"CPF1/1000G/{report_fname}\"), sep=\"\\t\"\n",
    ")\n",
    "hbg2_HGDP = pd.read_csv(os.path.join(RESULTSDIR, f\"CPF1/HGDP/{report_fname}\"), sep=\"\\t\")\n",
    "hbg2_GNOMAD = pd.read_csv(\n",
    "    os.path.join(RESULTSDIR, f\"CPF1/GNOMAD/{report_fname}\"), sep=\"\\t\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca4ce840",
   "metadata": {},
   "source": [
    "## Types of Retrieved Guide Candidates\n",
    "\n",
    "Here we classify all retrieved guide candidates according to their relationship \n",
    "with genetic variation. Each guide is assigned to one of the following categories:\n",
    "\n",
    "- Reference Guides: guides fully supported by the reference genome and unaffected \n",
    "    by observed variants.\n",
    "\n",
    "- PAM and Spacer Alternative Guides: guides that arise due to the presence of \n",
    "    genetic variants creating new protospacer or PAM sequences.\n",
    "\n",
    "- PAM Alternative Guides: guides that arise due to the presence of \n",
    "    genetic variants creating new PAM sequences.\n",
    "\n",
    "- Spacer Alternative Guides: guides that arise due to the presence of \n",
    "    genetic variants creating new protospacer sequences.\n",
    "\n",
    "The pie charts below summarize the relative proportion of each guide type among \n",
    "all retrieved candidates. This visualization provides an intuitive overview of \n",
    "how much of the guide space would be missed or mischaracterized by a reference-only \n",
    "approach and highlights the contribution of variant- and haplotype-aware guide \n",
    "discovery."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90a5ad9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "LABELS = [\n",
    "    \"Reference Guides\",\n",
    "    \"Spacer Alternative Guides\",\n",
    "    \"PAM Alternative Guides\",\n",
    "    \"PAM and Spacer Alternative Guides\",\n",
    "]\n",
    "\n",
    "\n",
    "def compute_guide_id_piechart(chrom, start, stop, strand, sgRNA_sequence, pam):\n",
    "    return f\"{chrom}_{start}_{stop}_{strand}_{sgRNA_sequence}_{pam}\"\n",
    "\n",
    "\n",
    "def has_lowercase(s):\n",
    "    return any(c.islower() for c in str(s))\n",
    "\n",
    "\n",
    "def retrieve_pie_chart_data(df):\n",
    "    df[\"guide_id\"] = df.apply(\n",
    "        lambda x: compute_guide_id_piechart(\n",
    "            x[\"chr\"], x[\"start\"], x[\"stop\"], x[\"strand\"], x[\"sgRNA_sequence\"], x[\"pam\"]\n",
    "        ),\n",
    "        axis=1,\n",
    "    )\n",
    "    df[\"category\"] = \"Unclassified\"  # default\n",
    "\n",
    "    # remove duplicate rows (same site and spacer+pam, different haplotype and scores)\n",
    "    df = df.drop_duplicates(subset=\"guide_id\")\n",
    "\n",
    "    # category 1: Reference Guides\n",
    "    df.loc[df[\"origin\"] == \"ref\", \"category\"] = \"Reference Guides\"\n",
    "\n",
    "    # category 2: PAM and Spacer Alternative Guides\n",
    "    mask_non_ref = df[\"origin\"] != \"ref\"\n",
    "    condition2 = (\n",
    "        mask_non_ref\n",
    "        & df[\"sgRNA_sequence\"].apply(has_lowercase)\n",
    "        & df[\"pam\"].apply(has_lowercase)\n",
    "    )\n",
    "    df.loc[condition2, \"category\"] = \"PAM and Spacer Alternative Guides\"\n",
    "\n",
    "    # category 3: PAM Alternative Guides\n",
    "    condition3 = (\n",
    "        mask_non_ref\n",
    "        & df[\"pam\"].apply(has_lowercase)\n",
    "        & ~df[\"sgRNA_sequence\"].apply(has_lowercase)\n",
    "    )\n",
    "    df.loc[condition3, \"category\"] = \"PAM Alternative Guides\"\n",
    "\n",
    "    # Category 4: Spacer Alternative Guides\n",
    "    condition4 = (\n",
    "        mask_non_ref\n",
    "        & df[\"sgRNA_sequence\"].apply(has_lowercase)\n",
    "        & ~df[\"pam\"].apply(has_lowercase)\n",
    "    )\n",
    "    df.loc[condition4, \"category\"] = \"Spacer Alternative Guides\"\n",
    "\n",
    "    unclassified_count = (df[\"category\"] == \"Unclassified\").sum()\n",
    "    assert unclassified_count == 0, f\"{unclassified_count} guides remain unclassified!\"\n",
    "\n",
    "    return [df[\"category\"].value_counts().get(cat, 0) for cat in LABELS]\n",
    "\n",
    "\n",
    "def piechart(ax, data, title):\n",
    "    # colors for each category\n",
    "    colors = [\"#aaa1cdff\", \"#92c1deff\", \"#ef86bdff\", \"#b8d8c8\"]\n",
    "    explode = (0, 0, 0.05, 0.1)\n",
    "\n",
    "    wedges, texts, autotexts = ax.pie(\n",
    "        data,\n",
    "        explode=explode,\n",
    "        colors=colors,\n",
    "        autopct=\"%1.2f%%\",\n",
    "        shadow=False,\n",
    "        startangle=140,\n",
    "        textprops={\"fontsize\": 16},\n",
    "        pctdistance=1.1,\n",
    "    )\n",
    "\n",
    "    ax.set_title(title, fontsize=20)\n",
    "    ax.axis(\"equal\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1551c00",
   "metadata": {},
   "source": [
    "Once defined the functions to plot our guide piechart, we display the gRNAs \n",
    "categories proportion in the three datasets on BCL11A enhancer region."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2be77632",
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = [\"1000G\", \"HGDP\", \"GNOMAD\"]\n",
    "data_report_map = {\"1000G\": bcl11a_1000G, \"HGDP\": bcl11a_HGDP, \"GNOMAD\": bcl11a_GNOMAD}\n",
    "\n",
    "f, axes = plt.subplots(1, 3, figsize=(30, 10))\n",
    "\n",
    "for ax, dataset in zip(axes, datasets):\n",
    "    title = f\"BCL11A +58 Erythroid Enhancer - {dataset}\"\n",
    "\n",
    "    # retrieve dataset-specific dataframe\n",
    "    pie_data = retrieve_pie_chart_data(data_report_map[dataset])\n",
    "    piechart(ax, pie_data, title)\n",
    "\n",
    "# single shared legend\n",
    "f.legend(LABELS, loc=\"lower center\", ncol=4, fontsize=16, frameon=False)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02870dd6",
   "metadata": {},
   "source": [
    "We repeat the analysis for HBG1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "621fc8a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = [\"1000G\", \"HGDP\", \"GNOMAD\"]\n",
    "data_report_map = {\"1000G\": hbg1_1000G, \"HGDP\": hbg1_HGDP, \"GNOMAD\": hbg1_GNOMAD}\n",
    "\n",
    "f, axes = plt.subplots(1, 3, figsize=(30, 10))\n",
    "\n",
    "for ax, dataset in zip(axes, datasets):\n",
    "    title = f\"HBG1 - {dataset}\"\n",
    "\n",
    "    # retrieve dataset-specific dataframe\n",
    "    pie_data = retrieve_pie_chart_data(data_report_map[dataset])\n",
    "    piechart(ax, pie_data, title)\n",
    "\n",
    "# single shared legend\n",
    "f.legend(LABELS, loc=\"lower center\", ncol=4, fontsize=16, frameon=False)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "392bbe7a",
   "metadata": {},
   "source": [
    "We repeat the analysis for HBG2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9a0c6ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = [\"1000G\", \"HGDP\", \"GNOMAD\"]\n",
    "data_report_map = {\"1000G\": hbg2_1000G, \"HGDP\": hbg2_HGDP, \"GNOMAD\": hbg2_GNOMAD}\n",
    "\n",
    "f, axes = plt.subplots(1, 3, figsize=(30, 10))\n",
    "\n",
    "for ax, dataset in zip(axes, datasets):\n",
    "    title = f\"HBG2 - {dataset}\"\n",
    "\n",
    "    # retrieve dataset-specific dataframe\n",
    "    pie_data = retrieve_pie_chart_data(data_report_map[dataset])\n",
    "    piechart(ax, pie_data, title)\n",
    "\n",
    "# single shared legend\n",
    "f.legend(LABELS, loc=\"lower center\", ncol=4, fontsize=16, frameon=False)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06ef69e1",
   "metadata": {},
   "source": [
    "## Guides On-Target Efficiency and Variant Effect on Alternative On-Targets \n",
    "\n",
    "Here we assess the predicted on-target efficiency of the retrieved guide candidates\n",
    "and investigate how genetic variation influences the presence and scoring of \n",
    "alternative on-targets.\n",
    "\n",
    "For each guide, CRISPR-HAWK computes an on-target efficiency score based on its \n",
    "spacer and PAM sequence. When variants alter either the spacer, the PAM, or both, \n",
    "alternative guide configurations may emerge at the same genomic locus. These \n",
    "alternatives can differ substantially in predicted efficiency compared to the \n",
    "reference guide.\n",
    "\n",
    "The following analyses focus on:\n",
    "\n",
    "- Comparing the efficiency of reference guides against their alternatives\n",
    "\n",
    "- Assessing whether genetoc variants may modulate the expected likelihood of\n",
    "    a guide designed on the reference to work properly on haplotype-specific\n",
    "    on-target sites\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef2950ea",
   "metadata": {},
   "source": [
    "Define global constants and special guide identifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09614df3",
   "metadata": {},
   "outputs": [],
   "source": [
    "SG1617 = \"chr2_60495261_-\"\n",
    "HBG1 = \"chr11_5249951_+\"\n",
    "HBG2 = \"chr11_5254875_+\"\n",
    "SAMPLE_COL = \"n_samples\"\n",
    "\n",
    "\n",
    "def compute_guide_id(chrom, start, strand):\n",
    "    return f\"{chrom}_{start}_{strand}\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad5f4bbf",
   "metadata": {},
   "source": [
    "Calculate score differences between reference and alternative guides"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a69dae0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_deltas(df, score_col):\n",
    "    df = df.copy()\n",
    "    use_abs = score_col != \"score_cfdon\"\n",
    "\n",
    "    def add_deltas(group):\n",
    "        ref = group[group[\"origin\"] == \"ref\"]\n",
    "        if ref.empty:\n",
    "            return group\n",
    "\n",
    "        ref_score = ref[score_col].iloc[0]\n",
    "        group[\"delta\"] = group[score_col] - ref_score\n",
    "        if use_abs:\n",
    "            group[\"abs_delta\"] = group[\"delta\"].abs()\n",
    "        return group\n",
    "\n",
    "    df[\"delta\"] = 0.0\n",
    "    if use_abs:\n",
    "        df[\"abs_delta\"] = 0.0\n",
    "\n",
    "    return df.groupby(\"guide_id\", group_keys=False).apply(add_deltas)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52028f46",
   "metadata": {},
   "source": [
    "Prepare top-ranked guides based on variant impact"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30785ebf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_data_by_delta(df, score_col, top_n, dataset_type):\n",
    "    df = df.copy()\n",
    "    df[\"guide_id\"] = df.apply(lambda x: compute_guide_id(x[0], x[1], x[6]), axis=1)\n",
    "    df = calculate_deltas(df, score_col)\n",
    "\n",
    "    # Group guides and extract ref/alt information\n",
    "    guide_data = {}\n",
    "    for guide_id, group in df.groupby(\"guide_id\", sort=False):\n",
    "        ref = group[group[\"origin\"] == \"ref\"]\n",
    "        if ref.empty:\n",
    "            continue\n",
    "\n",
    "        ref_row = ref.iloc[0]\n",
    "        alts = group[group[\"origin\"] == \"alt\"]\n",
    "\n",
    "        if score_col == \"score_cfdon\":\n",
    "            alts = alts[alts[score_col] < ref_row[score_col]]\n",
    "\n",
    "        alt_entries = [\n",
    "            {\n",
    "                \"alt_sgRNA\": alt[\"sgRNA_sequence\"],\n",
    "                \"pam\": alt[\"pam\"],\n",
    "                \"alt_score\": alt[score_col],\n",
    "                \"delta\": alt[\"delta\"],\n",
    "                \"abs_delta\": alt.get(\"abs_delta\", abs(alt[\"delta\"])),\n",
    "                SAMPLE_COL: alt[SAMPLE_COL],\n",
    "                \"variant_id\": alt[\"variant_id\"],\n",
    "            }\n",
    "            for _, alt in alts.iterrows()\n",
    "        ]\n",
    "\n",
    "        guide_data[guide_id] = {\n",
    "            \"ref_sgRNA\": ref_row[\"sgRNA_sequence\"],\n",
    "            \"pam\": ref_row[\"pam\"],\n",
    "            \"ref_score\": ref_row[score_col],\n",
    "            \"ref_samples\": ref_row[SAMPLE_COL],\n",
    "            \"alts\": alt_entries,\n",
    "        }\n",
    "\n",
    "    # Rank guides by worst variant effect\n",
    "    rankings = []\n",
    "    for gid, data in guide_data.items():\n",
    "        if not data[\"alts\"]:\n",
    "            worst = 0.0\n",
    "        elif score_col == \"score_cfdon\":\n",
    "            worst = min(a[\"delta\"] for a in data[\"alts\"])\n",
    "        else:\n",
    "            worst = max(a[\"abs_delta\"] for a in data[\"alts\"])\n",
    "        rankings.append((gid, worst))\n",
    "\n",
    "    worst_df = (\n",
    "        pd.DataFrame(rankings, columns=[\"guide_id\", \"delta\"])\n",
    "        .sort_values(\"delta\", ascending=(score_col == \"score_cfdon\"))\n",
    "        .reset_index(drop=True)\n",
    "    )\n",
    "\n",
    "    # Include special guide if present\n",
    "    if SG1617 in worst_df[\"guide_id\"].values:\n",
    "        special = worst_df[worst_df[\"guide_id\"] == SG1617]\n",
    "        others = worst_df[worst_df[\"guide_id\"] != SG1617].head(top_n - 1)\n",
    "        final_guides = pd.concat([special, others], ignore_index=True)\n",
    "    elif HBG1 in worst_df[\"guide_id\"].values:\n",
    "        special = worst_df[worst_df[\"guide_id\"] == HBG1]\n",
    "        others = worst_df[worst_df[\"guide_id\"] != HBG1].head(top_n - 1)\n",
    "        final_guides = pd.concat([special, others], ignore_index=True)\n",
    "    elif HBG2 in worst_df[\"guide_id\"].values:\n",
    "        special = worst_df[worst_df[\"guide_id\"] == HBG2]\n",
    "        others = worst_df[worst_df[\"guide_id\"] != HBG2].head(top_n - 1)\n",
    "        final_guides = pd.concat([special, others], ignore_index=True)\n",
    "    else:\n",
    "        final_guides = worst_df.head(top_n)\n",
    "\n",
    "    final_guides[\"Rank\"] = final_guides.index + 1\n",
    "\n",
    "    # Build wide-format dataframe\n",
    "    max_alts = max(len(guide_data[gid][\"alts\"]) for gid in final_guides[\"guide_id\"])\n",
    "    rows = []\n",
    "\n",
    "    for _, row in final_guides.iterrows():\n",
    "        gid = row[\"guide_id\"]\n",
    "        data = guide_data[gid]\n",
    "\n",
    "        out = {\n",
    "            \"guide_id\": gid,\n",
    "            \"Rank\": row[\"Rank\"],\n",
    "            \"ref_sgRNA\": data[\"ref_sgRNA\"],\n",
    "            \"pam\": data[\"pam\"],\n",
    "            \"ref_score\": data[\"ref_score\"],\n",
    "            \"ref_n_samples\": data[\"ref_samples\"],\n",
    "        }\n",
    "\n",
    "        for i, alt in enumerate(data[\"alts\"]):\n",
    "            prefix = f\"alt{i+1}_\"\n",
    "            out.update(\n",
    "                {\n",
    "                    f\"{prefix}sgRNA\": alt[\"alt_sgRNA\"],\n",
    "                    f\"{prefix}pam\": alt[\"pam\"],\n",
    "                    f\"{prefix}score\": alt[\"alt_score\"],\n",
    "                    f\"{prefix}delta\": alt[\"delta\"],\n",
    "                    f\"{prefix}abs_delta\": alt[\"abs_delta\"],\n",
    "                    f\"{prefix}{SAMPLE_COL}\": alt[SAMPLE_COL],\n",
    "                    f\"{prefix}variant_id\": alt[\"variant_id\"],\n",
    "                }\n",
    "            )\n",
    "\n",
    "        # Fill missing alt columns with NaN\n",
    "        for i in range(len(data[\"alts\"]), max_alts):\n",
    "            prefix = f\"alt{i+1}_\"\n",
    "            for k in [\n",
    "                \"sgRNA\",\n",
    "                \"pam\",\n",
    "                \"score\",\n",
    "                \"delta\",\n",
    "                \"abs_delta\",\n",
    "                SAMPLE_COL,\n",
    "                \"variant_id\",\n",
    "            ]:\n",
    "                out[f\"{prefix}{k}\"] = np.nan\n",
    "\n",
    "        rows.append(out)\n",
    "\n",
    "    return pd.DataFrame(rows)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2adc1e37",
   "metadata": {},
   "source": [
    "Utilities for plot sizing and styling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0df01ac0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_legend_size(n_samples, dataset_type):\n",
    "    if dataset_type == \"GNOMAD\":\n",
    "        thresholds = [1, 20, 50, 150, 500, np.inf]\n",
    "    else:\n",
    "        thresholds = [1, 20, 50, 100, 200, np.inf]\n",
    "\n",
    "    bases = [1, 10, 35, 75, 150, 300]\n",
    "    for limit, base in zip(thresholds, bases):\n",
    "        if n_samples <= limit:\n",
    "            return 150 * np.sqrt(base)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa7879bf",
   "metadata": {},
   "source": [
    "Create a dot plot showing variant effects across guides"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d39d3cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dotplot_delta(df, score_col, top_n, dataset_type):\n",
    "    top_df = df.sort_values(\"Rank\").head(top_n).copy()\n",
    "    top_df[\"rank_chr_start\"] = top_df.apply(\n",
    "        lambda row: f\"Rank {row['Rank']}, {row['guide_id'].split('_')[0]}:{row['guide_id'].split('_')[1]}\",\n",
    "        axis=1,\n",
    "    )\n",
    "\n",
    "    plt.figure(figsize=(22, 11))\n",
    "\n",
    "    # Generate color palette for variants\n",
    "    alt_cols = [\n",
    "        c for c in df.columns if c.startswith(\"alt\") and c.endswith(f\"_{SAMPLE_COL}\")\n",
    "    ]\n",
    "    variant_keys = list(\n",
    "        {\n",
    "            row[\"rank_chr_start\"]\n",
    "            for _, row in top_df.iterrows()\n",
    "            for col in alt_cols\n",
    "            if pd.notna(row[col]) and row[col] != \"REF\"\n",
    "        }\n",
    "    )\n",
    "\n",
    "    base_cmaps = [\n",
    "        \"Purples\",\n",
    "        \"Blues\",\n",
    "        \"Greens\",\n",
    "        \"Oranges\",\n",
    "        \"Reds\",\n",
    "        \"PuRd\",\n",
    "        \"RdPu\",\n",
    "        \"BuPu\",\n",
    "        \"GnBu\",\n",
    "        \"PuBuGn\",\n",
    "        \"BuGn\",\n",
    "        \"Spectral\",\n",
    "        \"coolwarm\",\n",
    "    ]\n",
    "    palette = [sns.color_palette(cmap, 9)[7] for cmap in base_cmaps]\n",
    "\n",
    "    if len(variant_keys) > len(palette):\n",
    "        palette += [\n",
    "            sns.color_palette(cmap, 9)[i] for i in range(6, 9) for cmap in base_cmaps\n",
    "        ][: len(variant_keys) - len(palette)]\n",
    "\n",
    "    random.shuffle(palette)\n",
    "    variant_colors = dict(zip(variant_keys, palette))\n",
    "\n",
    "    # Plot alternative alleles\n",
    "    for _, row in top_df.iterrows():\n",
    "        for i in range(1, 1000):\n",
    "            score_col_alt = f\"alt{i}_score\"\n",
    "            samples_col_alt = f\"alt{i}_{SAMPLE_COL}\"\n",
    "\n",
    "            if score_col_alt not in row or pd.isna(row[score_col_alt]):\n",
    "                break\n",
    "\n",
    "            n_samples = (\n",
    "                int(row[samples_col_alt]) if pd.notna(row[samples_col_alt]) else 1\n",
    "            )\n",
    "            plt.scatter(\n",
    "                row[\"Rank\"],\n",
    "                row[score_col_alt],\n",
    "                color=variant_colors.get(row[\"rank_chr_start\"], \"gray\"),\n",
    "                s=get_legend_size(n_samples, dataset_type),\n",
    "                alpha=0.6,\n",
    "                edgecolors=\"white\",\n",
    "                linewidth=0.5,\n",
    "                marker=\"D\" if n_samples == 1 else \"o\",\n",
    "                zorder=3,\n",
    "            )\n",
    "\n",
    "    # Plot reference alleles\n",
    "    if score_col == \"score_cfdon\":\n",
    "        plt.axhline(y=1, color=\"gray\", linestyle=\"-\", alpha=0.6, linewidth=3, zorder=5)\n",
    "        ref_legend = plt.Line2D(\n",
    "            [0], [0], color=\"gray\", linewidth=3, label=\"Reference\", alpha=0.6\n",
    "        )\n",
    "    else:\n",
    "        plt.scatter(\n",
    "            top_df[\"Rank\"],\n",
    "            top_df[\"ref_score\"],\n",
    "            color=\"black\",\n",
    "            s=600,\n",
    "            zorder=5,\n",
    "            edgecolors=\"white\",\n",
    "            linewidth=0.7,\n",
    "            label=\"Reference\",\n",
    "            alpha=0.6,\n",
    "        )\n",
    "        ref_legend = plt.Line2D(\n",
    "            [0],\n",
    "            [0],\n",
    "            marker=\"o\",\n",
    "            color=\"w\",\n",
    "            label=\"Reference\",\n",
    "            markerfacecolor=\"dimgray\",\n",
    "            alpha=0.6,\n",
    "            markersize=np.sqrt(600),\n",
    "            markeredgecolor=\"white\",\n",
    "            linewidth=0.7,\n",
    "        )\n",
    "\n",
    "    # Configure axes and labels\n",
    "    ax = plt.gca()\n",
    "    ax.set_xticks(top_df[\"Rank\"])\n",
    "    ax.set_xticklabels(\n",
    "        [row[\"ref_sgRNA\"] for _, row in top_df.iterrows()],\n",
    "        rotation=45,\n",
    "        ha=\"right\",\n",
    "        fontsize=15,\n",
    "    )\n",
    "\n",
    "    # Bold special guides\n",
    "    for label, gid in zip(ax.get_xticklabels(), top_df[\"guide_id\"].values):\n",
    "        if gid in [SG1617, HBG1, HBG2]:\n",
    "            label.set_weight(\"bold\")\n",
    "\n",
    "    plt.yticks(fontsize=15)\n",
    "    plt.xlabel(\"Guide\", fontsize=18)\n",
    "\n",
    "    ylabel = (\n",
    "        \"Variant Effect (CFD)\"\n",
    "        if score_col == \"score_cfdon\"\n",
    "        else f'On-Target Efficiency ({score_col.split(\"_\")[1].upper()})'\n",
    "    )\n",
    "    title = (\n",
    "        \"Variant Effect on Alternative On-Targets\"\n",
    "        if score_col == \"score_cfdon\"\n",
    "        else \"Guides On-Target Efficiency\"\n",
    "    )\n",
    "\n",
    "    plt.ylabel(ylabel, fontsize=19)\n",
    "    plt.title(title, fontsize=28)\n",
    "\n",
    "    # Create legend\n",
    "    legend_labels = [\"1\", \"2–20\", \"21–50\", \"51–100\", \"101–200\", \">200\"]\n",
    "    sample_counts = [1, 10, 35, 75, 150, 300]\n",
    "    markers = [\"D\"] + [\"o\"] * 5\n",
    "    scaled_sizes = [150 * np.sqrt(n) for n in sample_counts]\n",
    "\n",
    "    size_legend_handles = [\n",
    "        plt.Line2D(\n",
    "            [0],\n",
    "            [0],\n",
    "            marker=m,\n",
    "            color=\"w\",\n",
    "            label=l,\n",
    "            markerfacecolor=\"gray\",\n",
    "            markersize=np.sqrt(s),\n",
    "            alpha=0.6,\n",
    "        )\n",
    "        for l, s, m in zip(legend_labels, scaled_sizes, markers)\n",
    "    ]\n",
    "    size_legend_handles.insert(0, ref_legend)\n",
    "\n",
    "    legend = plt.legend(\n",
    "        handles=size_legend_handles,\n",
    "        title=\"Dot Size = #Samples\",\n",
    "        frameon=False,\n",
    "        bbox_to_anchor=(0.5, -0.55),\n",
    "        loc=\"lower center\",\n",
    "        ncol=7,\n",
    "        fontsize=11,\n",
    "        handletextpad=1,\n",
    "        columnspacing=5,\n",
    "        labelspacing=2,\n",
    "    )\n",
    "    legend.get_title().set_fontsize(24)\n",
    "\n",
    "    plt.ylim((-10, 110) if score_col == \"score_deepcpf1\" else (-0.05, 1.05))\n",
    "    plt.grid(True, alpha=0.3, linestyle=\"--\")\n",
    "    sns.despine()\n",
    "    plt.subplots_adjust(bottom=0.25)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d4162c6",
   "metadata": {},
   "source": [
    "Once defined the functions required to plot variants impact on guides efficiency\n",
    "and on-target activity, we focus again on BCL11A +58 Erythroid enhancer. For these\n",
    "analysis we combine the candidate guides using the variants from 1000G, HGDP, and\n",
    "gnomAD datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7948c591",
   "metadata": {},
   "outputs": [],
   "source": [
    "# combine data from different datasets\n",
    "for df in [bcl11a_1000G, bcl11a_HGDP, bcl11a_GNOMAD]:\n",
    "    if \"n_samples\" not in df.columns:\n",
    "        df[\"n_samples\"] = df[\"n_ref\"] if \"n_ref\" in df.columns else np.nan\n",
    "\n",
    "bcl11a_ALL = pd.concat(\n",
    "    [\n",
    "        bcl11a_1000G.assign(dataset=\"1000G\"),\n",
    "        bcl11a_HGDP.assign(dataset=\"HGDP\"),\n",
    "        bcl11a_GNOMAD.assign(dataset=\"GNOMAD\"),\n",
    "    ],\n",
    "    ignore_index=True,\n",
    ")\n",
    "\n",
    "dotplot_delta(\n",
    "    prepare_data_by_delta(bcl11a_ALL, \"score_azimuth\", 25, \"ALL\"),\n",
    "    \"score_azimuth\",\n",
    "    25,\n",
    "    \"ALL\",\n",
    ")\n",
    "dotplot_delta(\n",
    "    prepare_data_by_delta(bcl11a_ALL, \"score_cfdon\", 25, \"ALL\"),\n",
    "    \"score_cfdon\",\n",
    "    25,\n",
    "    \"ALL\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97ecfc62",
   "metadata": {},
   "source": [
    "We further analyze the impact of genetic variants on gRNAs predicted on-target \n",
    "efficiency by performing a dataset-wise breakdown:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "840b62fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "dotplot_delta(\n",
    "    prepare_data_by_delta(bcl11a_1000G, \"score_azimuth\", 25, \"1000G\"),\n",
    "    \"score_azimuth\",\n",
    "    25,\n",
    "    \"1000G\",\n",
    ")\n",
    "dotplot_delta(\n",
    "    prepare_data_by_delta(bcl11a_HGDP, \"score_azimuth\", 25, \"HGDP\"),\n",
    "    \"score_azimuth\",\n",
    "    25,\n",
    "    \"HGDP\",\n",
    ")\n",
    "dotplot_delta(\n",
    "    prepare_data_by_delta(bcl11a_GNOMAD, \"score_azimuth\", 25, \"GNOMAD\"),\n",
    "    \"score_azimuth\",\n",
    "    25,\n",
    "    \"GNOMAD\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "978dd447",
   "metadata": {},
   "source": [
    "We further analyze the impact of genetic variants on gRNAs residual on-target \n",
    "activity by performing a dataset-wise breakdown:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8d4ab8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "dotplot_delta(\n",
    "    prepare_data_by_delta(bcl11a_1000G, \"score_cfdon\", 25, \"1000G\"),\n",
    "    \"score_cfdon\",\n",
    "    25,\n",
    "    \"1000G\",\n",
    ")\n",
    "dotplot_delta(\n",
    "    prepare_data_by_delta(bcl11a_HGDP, \"score_cfdon\", 25, \"HGDP\"),\n",
    "    \"score_cfdon\",\n",
    "    25,\n",
    "    \"HGDP\",\n",
    ")\n",
    "dotplot_delta(\n",
    "    prepare_data_by_delta(bcl11a_GNOMAD, \"score_cfdon\", 25, \"GNOMAD\"),\n",
    "    \"score_cfdon\",\n",
    "    25,\n",
    "    \"GNOMAD\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7be6199c",
   "metadata": {},
   "source": [
    "We repeat the aggregated plot generation for HBG1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ed58224",
   "metadata": {},
   "outputs": [],
   "source": [
    "# combine data from different datasets\n",
    "for df in [hbg1_1000G, hbg1_HGDP, hbg1_GNOMAD]:\n",
    "    if \"n_samples\" not in df.columns:\n",
    "        df[\"n_samples\"] = df[\"n_ref\"] if \"n_ref\" in df.columns else np.nan\n",
    "\n",
    "hbg1_ALL = pd.concat(\n",
    "    [\n",
    "        hbg1_1000G.assign(dataset=\"1000G\"),\n",
    "        hbg1_HGDP.assign(dataset=\"HGDP\"),\n",
    "        hbg1_GNOMAD.assign(dataset=\"GNOMAD\"),\n",
    "    ],\n",
    "    ignore_index=True,\n",
    ")\n",
    "\n",
    "dotplot_delta(\n",
    "    prepare_data_by_delta(hbg1_ALL, \"score_deepcpf1\", 25, \"ALL\"),\n",
    "    \"score_deepcpf1\",\n",
    "    25,\n",
    "    \"ALL\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a751c7b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# combine data from different datasets\n",
    "for df in [hbg2_1000G, hbg2_HGDP, hbg2_GNOMAD]:\n",
    "    if \"n_samples\" not in df.columns:\n",
    "        df[\"n_samples\"] = df[\"n_ref\"] if \"n_ref\" in df.columns else np.nan\n",
    "\n",
    "hbg2_ALL = pd.concat(\n",
    "    [\n",
    "        hbg2_1000G.assign(dataset=\"1000G\"),\n",
    "        hbg2_HGDP.assign(dataset=\"HGDP\"),\n",
    "        hbg2_GNOMAD.assign(dataset=\"GNOMAD\"),\n",
    "    ],\n",
    "    ignore_index=True,\n",
    ")\n",
    "\n",
    "dotplot_delta(\n",
    "    prepare_data_by_delta(hbg2_ALL, \"score_deepcpf1\", 25, \"ALL\"),\n",
    "    \"score_deepcpf1\",\n",
    "    25,\n",
    "    \"ALL\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "072a3f3b",
   "metadata": {},
   "source": [
    "## Residual on-target activity vs guide specificity\n",
    "\n",
    "In this section we explore the relationship between residual on-target activity \n",
    "and guide specificity for the sg1617 reference guide and all variant-containing \n",
    "guide sequences derived from the same genomic site.\n",
    "\n",
    "Residual on-target activity measures how strongly a variant-derived guide is \n",
    "expected to cut at its (potentially altered) on-target site compared to the \n",
    "reference guide. Guide specificity instead reflects the likelihood that a guide \n",
    "may cut unintended off-target sites in the genome: higher values indicate better \n",
    "predicted specificity.\n",
    "\n",
    "To perform this analysis:\n",
    "\n",
    "- We collected reference and variant-derived guide sequences associated with \n",
    "sg1617.\n",
    "\n",
    "- For each sequence, CRISPR-HAWK computed its predicted on-target activity and \n",
    "derived the residual value with respect to the reference guide.\n",
    "\n",
    "- We retrieved guide specificity scores from the CRISPRme website reports.\n",
    "\n",
    "- Off-target nomination was performed with CRISPRme v2.1.7, using:\n",
    "    - NGG PAM\n",
    "    - 1000 Genomes Project + HGDP variant datasets\n",
    "    - up to 6 mismatches\n",
    "    - up to 2 DNA/RNA bulges\n",
    "\n",
    "The resulting scatter plot visualizes each guide configuration as a point in the \n",
    "activity–specificity space. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4432008b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def CFD_ONvsOFF(df):\n",
    "    alt_colors = [\"#1f77b4\", \"#2ca02c\", \"#ff7f0e\", \"#c212b0\"]\n",
    "    color_map = {\"REF\": \"grey\"}\n",
    "\n",
    "    alt_ids = [v for v in df[\"variant_id\"].unique() if v != \"REF\"]\n",
    "    for i, alt_id in enumerate(alt_ids):\n",
    "        color_map[alt_id] = alt_colors[i % len(alt_colors)]\n",
    "\n",
    "    for gene in df[\"gene\"].unique():\n",
    "        subset = df[(df[\"gene\"] == gene)]\n",
    "\n",
    "        fig, ax = plt.subplots(figsize=(6, 6))\n",
    "\n",
    "        x = np.linspace(-0.1, 1.1, 256)\n",
    "        y = np.linspace(-0.1, 1.1, 256)\n",
    "        X, Y = np.meshgrid(x, y)\n",
    "        diagonal_distance = (X + Y) / 2.2\n",
    "        colors = [\"#B30000\", \"#FF4444\", \"#FFAAAA\", \"white\"]\n",
    "        n_bins = 256\n",
    "        cmap = LinearSegmentedColormap.from_list(\"custom_gradient\", colors, N=n_bins)\n",
    "        im = plt.imshow(\n",
    "            diagonal_distance,\n",
    "            extent=[-0.4, 1.1, -0.4, 1.1],\n",
    "            origin=\"lower\",\n",
    "            cmap=cmap,\n",
    "            aspect=\"auto\",\n",
    "            alpha=0.3,\n",
    "            zorder=0,\n",
    "        )\n",
    "\n",
    "        variant_handles = {}\n",
    "        for _, row in subset.iterrows():\n",
    "            marker = \"D\" if row[\"n_samples\"] == 1 else \"o\"\n",
    "            color = color_map[row[\"variant_id\"]]\n",
    "            size = 150 * np.sqrt(row[\"n_samples\"])\n",
    "            plt.scatter(\n",
    "                row[\"off_target\"],\n",
    "                row[\"on_target\"],\n",
    "                color=color,\n",
    "                s=size,\n",
    "                alpha=0.6,\n",
    "                marker=marker,\n",
    "                edgecolors=\"white\",\n",
    "                linewidth=0.5,\n",
    "                zorder=2,\n",
    "            )\n",
    "            if row[\"variant_id\"] not in variant_handles:\n",
    "                variant_marker = (\n",
    "                    \"D\"\n",
    "                    if (\n",
    "                        subset[\n",
    "                            (subset[\"variant_id\"] == row[\"variant_id\"])\n",
    "                            & (subset[\"n_samples\"] == 1)\n",
    "                        ].shape[0]\n",
    "                        > 0\n",
    "                    )\n",
    "                    else \"o\"\n",
    "                )\n",
    "                handle = Line2D(\n",
    "                    [0],\n",
    "                    [0],\n",
    "                    marker=variant_marker,\n",
    "                    color=\"w\",\n",
    "                    markerfacecolor=color,\n",
    "                    markeredgecolor=\"white\",\n",
    "                    markersize=8,\n",
    "                    linewidth=0,\n",
    "                    label=(\n",
    "                        \"Reference\" if row[\"variant_id\"] == \"REF\" else row[\"variant_id\"]\n",
    "                    ),\n",
    "                    alpha=0.8,\n",
    "                )\n",
    "                variant_handles[row[\"variant_id\"]] = handle\n",
    "\n",
    "        plt.xlabel(\"Guide specifity\", fontsize=10)\n",
    "        plt.ylabel(\"Residual on-target activity\", fontsize=10)\n",
    "        plt.xticks(fontsize=10)\n",
    "        plt.yticks(fontsize=10)\n",
    "        plt.xlim(-0.05, 1.1)\n",
    "        plt.ylim(-0.05, 1.1)\n",
    "        plt.grid(True, alpha=0.3, linestyle=\"--\", zorder=1, color=\"black\")\n",
    "        plt.gca().set_axisbelow(True)\n",
    "\n",
    "        cbar = fig.colorbar(im, ax=ax, fraction=0.025, pad=0.08, shrink=0.5)\n",
    "        cbar.set_label(\n",
    "            \"Guide Penalty\\n(Low → High)\", rotation=270, labelpad=25, fontsize=8\n",
    "        )\n",
    "        cbar.set_ticks([])\n",
    "        plt.gca().set_aspect(\"equal\", adjustable=\"datalim\")\n",
    "\n",
    "        legend_labels = [\"1 sample\", \"2-20 samples\", \">20 samples\"]\n",
    "        sample_counts = [1, 10, 35]  # usa il valore reale per REF\n",
    "        markers = [\"D\", \"o\", \"o\"]  # marker per ciascuno\n",
    "        scaled_sizes = [150 * np.sqrt(n) for n in sample_counts]  # scala proporzionale\n",
    "\n",
    "        size_handles = [\n",
    "            Line2D(\n",
    "                [0],\n",
    "                [0],\n",
    "                marker=marker,\n",
    "                color=\"w\",\n",
    "                label=label,\n",
    "                markerfacecolor=\"gray\" if i < 2 else \"grey\",  # REF in grey\n",
    "                markersize=np.sqrt(size),\n",
    "                alpha=0.6,\n",
    "            )\n",
    "            for i, (label, size, marker) in enumerate(\n",
    "                zip(legend_labels, scaled_sizes, markers)\n",
    "            )\n",
    "        ]\n",
    "\n",
    "        l1 = plt.legend(\n",
    "            handles=list(variant_handles.values()),\n",
    "            fontsize=8,\n",
    "            title_fontsize=9,\n",
    "            loc=\"lower right\",\n",
    "            frameon=False,\n",
    "            bbox_to_anchor=(1.2, 0),\n",
    "        )\n",
    "        plt.gca().add_artist(l1)\n",
    "        plt.legend(\n",
    "            handles=size_handles,\n",
    "            frameon=False,\n",
    "            labelspacing=1.2,\n",
    "            ncol=len(size_handles),\n",
    "            loc=\"lower center\",\n",
    "            bbox_to_anchor=(0.5, -0.25),\n",
    "        )\n",
    "        sns.despine()\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df7bfd6f",
   "metadata": {},
   "source": [
    "Once defined the plot function, we generate the plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69f870ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# gRNA specificieties retrieved from crisprme website, residual on-target\n",
    "# activity retrieved from crisprhawk reports (score_cfdon column)\n",
    "sg1617_combined = pd.DataFrame(\n",
    "    [\n",
    "        (\"sg1617\", \"ref\", 1.0, 0.63, \"REF\", 30),\n",
    "        (\"sg1617\", \"alt1\", 0, 0.38, \"chr2-60495268-T/G\", 3),\n",
    "        (\"sg1617\", \"alt2\", 0.33, 0.466, \"chr2-60495273-G/A\", 1),\n",
    "        (\"sg1617\", \"alt3\", 0, 0.307, \"chr2-60495268-T/G,chr2-60495273-G/A\", 4),\n",
    "        (\"sg1617\", \"alt4\", 0.9, 0.656, \"chr2-60495283-G/C\", 1),\n",
    "    ],\n",
    "    columns=[\"gene\", \"type\", \"on_target\", \"off_target\", \"variant_id\", \"n_samples\"],\n",
    ")\n",
    "\n",
    "CFD_ONvsOFF(sg1617_combined)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69e501be",
   "metadata": {},
   "source": [
    "## Residual on-target activity of therapeutic and benchmark gRNAs across variant-containing target sites\n",
    "\n",
    "In this cell, we evaluate how genetic variation influences the predicted on-target activity of both therapeutic and benchmark gRNAs. \n",
    "\n",
    "To quantify the effect of sequence variation on cleavage efficiency, we computed \n",
    "CFD scores for each reference-designed gRNA against all variant-containing \n",
    "target sequences overlapping its intended on-target site. Each point in the plot \n",
    "corresponds to a distinct haplotype or allele configuration carrying one or more \n",
    "variants. Point size reflects the number of individuals harboring that sequence, \n",
    "thereby linking functional impact with population frequency."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15167f0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define therapeutic guides data\n",
    "th_guides = {\n",
    "    \"CCR5_1\": (\n",
    "        \"crisprhawk_guides__chr3_46372162_46374162_NGG_20_nsamples.tsv\",\n",
    "        46373163,\n",
    "    ),\n",
    "    \"CCR5_2\": (\n",
    "        \"crisprhawk_guides__chr3_46372138_46374138_NGG_20_nsamples.tsv\",\n",
    "        46373139,\n",
    "    ),\n",
    "    \"TRBC1\": (\n",
    "        \"crisprhawk_guides__chr7_142791004_142793004_NGG_20_nsamples.tsv\",\n",
    "        142792004,\n",
    "    ),\n",
    "    \"TRBC2\": (\n",
    "        \"crisprhawk_guides__chr7_142800351_142802350_NGG_20_nsamples.tsv\",\n",
    "        142801351,\n",
    "    ),\n",
    "    \"HBB_1\": (\"crisprhawk_guides__chr11_5225967_5227967_NGG_20_nsamples.tsv\", 5226968),\n",
    "    \"HBB_2\": (\"crisprhawk_guides__chr11_5225803_5227803_NGG_20_nsamples.tsv\", 5226804),\n",
    "    \"FANCF\": (\n",
    "        \"crisprhawk_guides__chr11_22624785_22626785_NGG_20_nsamples.tsv\",\n",
    "        22625786,\n",
    "    ),\n",
    "    \"HBG1\": (\"crisprhawk_guides__chr11_5248955_5250955_NGG_20_nsamples.tsv\", 5249956),\n",
    "    \"EMX1\": (\"crisprhawk_guides__chr2_72932853_72934853_NGG_20_nsamples.tsv\", 72933853),\n",
    "    \"HBG2\": (\"crisprhawk_guides__chr11_5253879_5255879_NGG_20_nsamples.tsv\", 5254880),\n",
    "    \"BCL11A\": (\n",
    "        \"crisprhawk_guides__chr2_60495215_60496479_NGG_20_nsamples.tsv\",\n",
    "        60495261,\n",
    "    ),\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c92f4152",
   "metadata": {},
   "source": [
    "The next cell defines the functions to process the reports and generate the plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e8ea9b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_report(report_fname, pos, target):\n",
    "    df = pd.read_csv(report_fname, sep=\"\\t\").sort_values(by=[\"start\", \"origin\"])\n",
    "    df_th = df[df[\"start\"] == pos]\n",
    "    df_th[\"label\"] = f\"{target}:{pos}\"\n",
    "    return df_th\n",
    "\n",
    "\n",
    "def TG_Dotplot_CFDOn(df):\n",
    "    plt.figure(figsize=(28, 9))\n",
    "    df = df.sort_values(by=\"label\", ascending=True).reset_index(drop=True)\n",
    "    df = df[df[\"origin\"] != \"ref\"]\n",
    "\n",
    "    labels = df[\"label\"].unique()\n",
    "    cmap = cm.get_cmap(\"tab20\", len(labels))\n",
    "    label_colors = {label: cmap(i) for i, label in enumerate(labels)}\n",
    "\n",
    "    df[\"n_samples\"] = df[\"n_samples\"].fillna(1)\n",
    "    df[\"dot_size\"] = df[\"n_samples\"].apply(lambda x: 150 * np.sqrt(x))\n",
    "\n",
    "    n_labels = len(labels)\n",
    "    x = np.linspace(-0.5, n_labels - 0.5, 256)\n",
    "    y = np.linspace(-0.1, 1.1, 256)\n",
    "    X, Y = np.meshgrid(x, y)\n",
    "\n",
    "    vertical_distance = (Y - (-0.1)) / (1.1 - (-0.1))\n",
    "\n",
    "    colors = [\"#B30000\", \"#FF4444\", \"#FFAAAA\", \"white\"]\n",
    "    gradient_cmap = LinearSegmentedColormap.from_list(\"custom_gradient\", colors, N=256)\n",
    "\n",
    "    im = plt.imshow(\n",
    "        vertical_distance,\n",
    "        extent=[-0.5, n_labels - 0.5, -0.1, 1.1],\n",
    "        origin=\"lower\",\n",
    "        cmap=gradient_cmap,\n",
    "        aspect=\"auto\",\n",
    "        alpha=0.3,\n",
    "        zorder=0,\n",
    "    )\n",
    "\n",
    "    for i, row in df.iterrows():\n",
    "        marker = \"D\" if (row[\"n_samples\"] == 1) else \"o\"\n",
    "        alpha_val = 0.6\n",
    "        color_val = label_colors[row[\"label\"]]\n",
    "        x_pos = np.where(labels == row[\"label\"])[0][0]\n",
    "\n",
    "        plt.scatter(\n",
    "            x_pos,\n",
    "            row[\"score_cfdon\"],\n",
    "            alpha=alpha_val,\n",
    "            c=[color_val],\n",
    "            s=row[\"dot_size\"],\n",
    "            marker=marker,\n",
    "            edgecolors=\"white\",\n",
    "            linewidth=0.5,\n",
    "            zorder=2,\n",
    "        )\n",
    "\n",
    "    legend_labels = [\n",
    "        \"1 sample\",\n",
    "        \"2-20 samples\",\n",
    "        \"21-50 samples\",\n",
    "        \"51-100 samples\",\n",
    "        \"101-200 samples\",\n",
    "        \">200 samples\",\n",
    "    ]\n",
    "    sample_counts = [1, 10, 35, 75, 150, 300]\n",
    "    markers = [\"D\", \"o\", \"o\", \"o\", \"o\", \"o\"]\n",
    "    scaled_sizes = [150 * np.sqrt(n) for n in sample_counts]\n",
    "    ref_handle = Line2D(\n",
    "        [0], [0], color=\"gray\", linestyle=\"-\", linewidth=3, label=\"Reference\", alpha=0.6\n",
    "    )\n",
    "    size_handles = [\n",
    "        plt.Line2D(\n",
    "            [0],\n",
    "            [0],\n",
    "            marker=marker,\n",
    "            color=\"w\",\n",
    "            label=label,\n",
    "            markerfacecolor=\"gray\",\n",
    "            markersize=np.sqrt(size),\n",
    "            alpha=0.6,\n",
    "        )\n",
    "        for label, size, marker in zip(legend_labels, scaled_sizes, markers)\n",
    "    ]\n",
    "    all_handles = [ref_handle] + size_handles\n",
    "    plt.legend(\n",
    "        handles=all_handles,\n",
    "        frameon=False,\n",
    "        labelspacing=1.5,\n",
    "        ncol=len(all_handles),\n",
    "        loc=\"lower center\",\n",
    "        bbox_to_anchor=(0.5, -0.45),\n",
    "        prop={\"size\": 14},\n",
    "    )\n",
    "\n",
    "    plt.title(\n",
    "        \"Residual activity of the on-target reference on alternative haplotypes of therapeutic guides\",\n",
    "        fontsize=18,\n",
    "    )\n",
    "    plt.xlabel(\"Guide:Start\", fontsize=15)\n",
    "    plt.ylabel(\"Residual on-target activity\", fontsize=15)\n",
    "\n",
    "    ax = plt.gca()\n",
    "    ax.spines[\"top\"].set_visible(False)\n",
    "    ax.spines[\"right\"].set_visible(False)\n",
    "    plt.xticks(range(n_labels), labels, fontsize=15, rotation=45, ha=\"right\")\n",
    "    plt.yticks(fontsize=15)\n",
    "    plt.ylim(-0.1, 1.1)\n",
    "    plt.xlim(-0.5, n_labels - 0.5)\n",
    "    plt.grid(True, alpha=0.3, linestyle=\"--\", zorder=1, color=\"black\")\n",
    "    plt.axhline(y=1, color=\"gray\", linestyle=\"-\", linewidth=3, alpha=0.6, zorder=1)\n",
    "\n",
    "    cbar = plt.colorbar(im, ax=ax, fraction=0.015, pad=0.02, shrink=0.6)\n",
    "    cbar.set_label(\n",
    "        \"Guide Penalty\\n(Low → High)\", rotation=270, labelpad=25, fontsize=12\n",
    "    )\n",
    "    cbar.set_ticks([])\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14a7cd30",
   "metadata": {},
   "source": [
    "The next cell generates the plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e506f196",
   "metadata": {},
   "outputs": [],
   "source": [
    "th_reports_1000G = pd.concat(\n",
    "    [\n",
    "        preprocess_report(\n",
    "            os.path.join(RESULTSDIR, \"CAS9/1000G\", report_fname), pos, target\n",
    "        )\n",
    "        for target, (report_fname, pos) in th_guides.items()\n",
    "    ],\n",
    "    ignore_index=True,\n",
    ")\n",
    "th_reports_1000G[\"dataset\"] = \"1000G\"\n",
    "th_reports_HGDP = pd.concat(\n",
    "    [\n",
    "        preprocess_report(\n",
    "            os.path.join(RESULTSDIR, \"CAS9/HGDP\", report_fname), pos, target\n",
    "        )\n",
    "        for target, (report_fname, pos) in th_guides.items()\n",
    "    ],\n",
    "    ignore_index=True,\n",
    ")\n",
    "th_reports_HGDP[\"dataset\"] = \"HGDP\"\n",
    "th_reports_GNOMAD = pd.concat(\n",
    "    [\n",
    "        preprocess_report(\n",
    "            os.path.join(RESULTSDIR, \"CAS9/GNOMAD\", report_fname), pos, target\n",
    "        )\n",
    "        for target, (report_fname, pos) in th_guides.items()\n",
    "    ],\n",
    "    ignore_index=True,\n",
    ")\n",
    "th_reports_GNOMAD[\"dataset\"] = \"GNOMAD\"\n",
    "th_report = pd.concat(\n",
    "    [th_reports_1000G, th_reports_HGDP, th_reports_GNOMAD], ignore_index=True\n",
    ")\n",
    "th_report[\"sgRNA_sequence\"] = th_report[\"sgRNA_sequence\"].str.upper()\n",
    "th_report[\"label\"] = th_report[\"label\"].replace({\"BCL11A:60495261\": \"sg1617\"})\n",
    "all_labels = th_report[\"label\"].unique().tolist()\n",
    "ordered_labels = [\"sg1617\"] + sorted([lab for lab in all_labels if lab != \"sg1617\"])\n",
    "th_report[\"label\"] = pd.Categorical(\n",
    "    th_report[\"label\"], categories=ordered_labels, ordered=True\n",
    ")\n",
    "combined_all = th_report.sort_values(by=\"label\").reset_index(drop=True)\n",
    "TG_Dotplot_CFDOn(combined_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9debd204",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "data-analysis-ngs",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
