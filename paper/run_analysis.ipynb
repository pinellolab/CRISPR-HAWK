{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bb5b92dd",
   "metadata": {},
   "source": [
    "# Reproduce the results presented in \"CRISPR-HAWK: Haplotype- and Variant-Aware Guide Design Toolkit for CRISPR-Cas\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e48317ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import subprocess\n",
    "import random\n",
    "import pysam\n",
    "import os\n",
    "\n",
    "# from tqdm import tqdm\n",
    "from time import time\n",
    "from matplotlib.lines import Line2D\n",
    "from matplotlib.font_manager import FontProperties\n",
    "from matplotlib.colors import LinearSegmentedColormap"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5b930a4",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "CRISPR-HAWK is a comprehensive and scalable framework for designing guide RNAs \n",
    "(gRNAs) and evaluating the impact of genetic variation on CRISPR-Cas on-target \n",
    "activity. Developed as an offline, user-friendly command-line tool, CRISPR-HAWK \n",
    "integrates large-scale human variation datasets, including the 1000 Genomes Project, \n",
    "the Human Genome Diversity Project (HGDP), and gnomAD, with orthogonal \n",
    "genomic annotations to systematically prioritize gRNAs targeting regions of interest.\n",
    "\n",
    "The framework is Cas-agnostic and supports a broad range of nucleases, such as \n",
    "Cas9, SaCas9, and Cpf1 (Cas12a), while also allowing full customization of PAM \n",
    "sequences and guide lengths. This flexibility ensures compatibility with emerging \n",
    "CRISPR technologies and enables users to tailor gRNA design to specific experimental \n",
    "needs.\n",
    "\n",
    "CRISPR-HAWK incorporates both single-nucleotide variants (SNVs) and small \n",
    "insertions and deletions (indels), and it natively handles individual- and \n",
    "population-specific haplotypes. This makes it particularly suitable for personalized \n",
    "genome editing as well as population-scale analyses. The workflow, from variant-aware \n",
    "preprocessing to gRNA discovery, is fully automated, generating ranked candidate \n",
    "gRNAs, annotated target sequences, and publication-ready visualizations.\n",
    "\n",
    "Thanks to its modular architecture, CRISPR-HAWK can be seamlessly integrated with \n",
    "downstream tools such as CRISPRme or CRISPRitz for comprehensive off-target prediction \n",
    "and follow-up analysis of prioritized guides.\n",
    "\n",
    "This notebook reproduce the results presented in |||**add paper-link**|||."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c26072b6",
   "metadata": {},
   "source": [
    "## Download data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55f51b00",
   "metadata": {},
   "source": [
    "### Downloading Genetic Variation Datasets (1000 Genomes, HGDP, gnomAD)\n",
    "\n",
    "CRISPR-HAWK supports large-scale genetic diversity analyses by integrating variation \n",
    "from several major population genomics resources. This section provides instructions \n",
    "for downloading the VCF files required to reproduce the results presented in the paper.\n",
    "\n",
    "**Overview of Supported Datasets**\n",
    "\n",
    "- 1000 Genomes Project (Phase 3)\n",
    "  <br>2,504 individuals from 26 global populations; whole-genome sequencing at ~30×.\n",
    "\n",
    "- Human Genome Diversity Project (HGDP)\n",
    "  <br>929 individuals from globally diverse populations; high-coverage WGS.\n",
    "\n",
    "- gnomAD (v4.1)\n",
    "  <br>Population-scale aggregated variation from ~76,000 genomes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07b4b94a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define datasets urls\n",
    "url_hgdp = (\n",
    "    \"https://ngs.sanger.ac.uk/production/hgdp/hgdp_wgs.20190516/\" \n",
    "    \"hgdp_wgs.20190516.full.chr{}.vcf.gz\"\n",
    ")\n",
    "url_1kgp = (\n",
    "    \"ftp://ftp.1000genomes.ebi.ac.uk/vol1/ftp/data_collections/\"\n",
    "    \"1000_genomes_project/release/20190312_biallelic_SNV_and_INDEL/\" \n",
    "    \"ALL.chr{}.shapeit2_integrated_snvindels_v2a_27022019.GRCh38.phased.vcf.gz\"\n",
    ")\n",
    "url_gnomad = (\n",
    "    \"https://storage.googleapis.com/gcp-public-data--gnomad/release/4.1/vcf/\" \n",
    "    \"genomes/gnomad.genomes.v4.1.sites.chr{}.vcf.bgz\"\n",
    ")\n",
    "variants = {\"HGDP\": url_hgdp, \"1000G\": url_1kgp, \"GNOMAD\": url_gnomad}\n",
    "\n",
    "# define chromosomes\n",
    "chroms = [2, 3, 7, 11]\n",
    "\n",
    "# download files\n",
    "for dataset, url in variants.items():\n",
    "    vcfdir = os.path.join(\"vcf\", dataset)\n",
    "    if dataset == \"GNOMAD\":\n",
    "        vcfdir = os.path.join(vcfdir, \"raw\")\n",
    "    os.makedirs(vcfdir, exist_ok=True)  # create dataset folder \n",
    "    for c in chroms:        \n",
    "        # download VCF and index\n",
    "        ! wget -P {vcfdir} {url.format(c)}\n",
    "        ! wget -P {vcfdir} {url.format(c)}.tbi"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6f2b59c",
   "metadata": {},
   "source": [
    "Unlike the 1000 Genomes and HGDP callsets, the gnomAD VCFs contain allele frequency \n",
    "information only and do not provide individual-level genotype data. Since \n",
    "CRISPR-HAWK requires genotypes to reconstruct haplotypes and perform variant-aware \n",
    "gRNA discovery, gnomAD VCFs must first be converted into a compatible, pseudo-genotyped \n",
    "format. To enable this, we use the CRISPR-HAWK VCF converter, which generates a \n",
    "CRISPR-HAWK–ready VCF while preserving population-level allele distributions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcd930da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check gnomad folder exists\n",
    "gnomad_dir = \"vcf/GNOMAD\"\n",
    "gnomad_raw_dir = os.path.join(gnomad_dir, \"raw\")\n",
    "assert os.path.isdir(gnomad_raw_dir)\n",
    "\n",
    "# create converted VCFs folder\n",
    "gnomad_gt_dir = os.path.join(gnomad_dir, \"genotype\")\n",
    "os.makedirs(gnomad_gt_dir, exist_ok=True)\n",
    "\n",
    "# convert gnoamd VCFs using crisprhawk\n",
    "! crisprhawk convert-gnomad-vcf -d {gnomad_raw_dir} -o {gnomad_gt_dir}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a6a36a1",
   "metadata": {},
   "source": [
    "### Downloading the hg38 Reference Genome\n",
    "\n",
    "CRISPR-HAWK requires a reference genome to extract genomic contexts, evaluate \n",
    "variant-aware target sequences, and correctly map gRNA target sites. In this \n",
    "section, we download the primary assembly FASTA filesfrom the Genome Reference \n",
    "Consortium–maintained repositories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34d9e1bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define chromosomes\n",
    "chroms = [2, 3, 7, 11]\n",
    "\n",
    "# create genome folder\n",
    "genome_dir = \"genome\"\n",
    "os.makedirs(genome_dir, exist_ok=True)\n",
    "\n",
    "# define genome url\n",
    "url_ucsc = (\n",
    "    \"https://hgdownload.soe.ucsc.edu/goldenpath/hg38/chromosomes/chr{}.fa.gz\"\n",
    ")\n",
    "\n",
    "# Download and unzip FASTA file for each chromosome\n",
    "for c in chroms:\n",
    "    print(f\"Downloading FASTA for chromosome {c}\")\n",
    "    ! wget -nc -P {genome_dir} {url_ucsc.format(c)}\n",
    "    ! gunzip -f {genome_dir}/chr{c}.fa.gz"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5f39fe4",
   "metadata": {},
   "source": [
    "### Creating BED Files for the Analyzed Regions\n",
    "\n",
    "CRISPR-HAWK requires BED files to define the genomic intervals where gRNA discovery \n",
    "and variant-aware analysis will be performed. Each BED file specifies one or more \n",
    "regions of interest in the standard 3-column BED format:\n",
    "```\n",
    "chrom   start   end\n",
    "```\n",
    "\n",
    "Coordinates must reference the hg38 genome assembly (or whichever reference you \n",
    "downloaded in the previous step)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b476416",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create region folder\n",
    "regions_dir = \"regions\"\n",
    "os.makedirs(regions_dir, exist_ok=True)\n",
    "\n",
    "# define regions\n",
    "regions = {\n",
    "    \"BCL11A\": [\"chr2\", 60495215, 60496479],\n",
    "    \"EMX1\":   [\"chr2\", 72932853, 72934853],\n",
    "    \"CCR5_1\":   [\"chr3\", 46372138, 46374138],\n",
    "    \"CCR5_2\":   [\"chr3\", 46372162, 46374162],\n",
    "    \"TRBC1\":  [\"chr7\", 142791004, 142793004],\n",
    "    \"TRBC2\":  [\"chr7\", 142800351, 142802350],\n",
    "    \"HBB_1\":    [\"chr11\", 5225803, 5227803],\n",
    "    \"HBB_2\":    [\"chr11\", 5225967, 5227967],\n",
    "    \"HBG2_CAS9\":   [\"chr11\", 5252879, 5256879],\n",
    "    \"HBG1_CAS9\":   [\"chr11\", 5248955, 5250955],\n",
    "    \"HBG2_CPF1\":   [\"chr11\", 5253874, 5255874],\n",
    "    \"HBG1_CPF1\":   [\"chr11\", 5248950, 5250950],\n",
    "    \"FANCF\":  [\"chr11\", 22624785, 22626785],\n",
    "}\n",
    "\n",
    "# create bed files \n",
    "for gene, (chrom, start, end) in regions.items():\n",
    "    bed_fname = os.path.join(regions_dir, f\"{gene}.bed\")\n",
    "    with open(bed_fname, mode=\"w\") as f:\n",
    "        f.write(f\"{chrom}\\t{start}\\t{end}\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4ef53cb",
   "metadata": {},
   "source": [
    "## Variant-Aware gRNA Retrieval on Defined Regions\n",
    "\n",
    "With the reference genome, variant datasets, and BED files prepared, CRISPR-HAWK\n",
    "can now retrieve all candidate gRNAs within the specified regions while accounting\n",
    "for genetic variation across populations and individuals. This step is central to \n",
    "CRISPR-HAWK’s design philosophy: guide discovery must be variant-aware, ensuring \n",
    "that both reference and haplotype-specific target sequences are evaluated.\n",
    "\n",
    "**What This Step Does**\n",
    "\n",
    "For each genomic interval listed in the BED file(s), CRISPR-HAWK:\n",
    "\n",
    "- Extracts the reference sequence from hg38.\n",
    "\n",
    "- Applies all relevant variants (SNVs and indels) from the loaded dataset,\n",
    "including 1000G, HGDP, or converted gnomAD, to reconstruct individual, and population-specific haplotypes.\n",
    "\n",
    "- Scans both the reference and haplotype sequences to identify all gRNAs that match the user-defined:\n",
    "\n",
    "    - PAM sequence (e.g., NGG, NAA, TTTV, …)\n",
    "\n",
    "    - guide length\n",
    "\n",
    "    - nuclease type (Cas9, SaCas9, Cpf1/Cas12a, etc.)\n",
    "\n",
    "- Reports each gRNA along with:\n",
    "\n",
    "    - its exact reference and alternative alleles\n",
    "\n",
    "    - per-haplotype presence/absence\n",
    "\n",
    "    - the samples in which the target site is altered\n",
    "\n",
    "    - summary metrics for prioritization\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2587f587",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define target regions\n",
    "targets = [\n",
    "    \"BCL11A\",\n",
    "    \"EMX1\",\n",
    "    \"CCR5_1\",\n",
    "    \"CCR5_2\",\n",
    "    \"TRBC1\",\n",
    "    \"TRBC2\",\n",
    "    \"FANCF\",\n",
    "    \"HBB_1\",\n",
    "    \"HBB_2\",\n",
    "    \"HBG1_CAS9\",\n",
    "    \"HBG2_CAS9\",\n",
    "    \"HBG1_CPF1\",\n",
    "    \"HBG1_CPF1\",\n",
    "]\n",
    "\n",
    "# define genetic variants datasets\n",
    "datasets = [\"1000G\", \"HGDP\", \"gnomAD\"]\n",
    "\n",
    "# define pams\n",
    "pams = [\"NGG\", \"TTTV\"] # Cas9, Cas12\n",
    "guide_lens = [20, 23]\n",
    "thread = 16\n",
    "\n",
    "# define folders \n",
    "genome_dir = \"genome\"\n",
    "variants_dir = \"vcf\"\n",
    "regions_dir = \"regions\"\n",
    "results_dir = \"results\"\n",
    "\n",
    "# create results folder\n",
    "os.makedirs(results_dir, exist_ok=True)\n",
    "\n",
    "# run guide design with crisprhawk\n",
    "for dataset in datasets:\n",
    "    vcfdir = os.path.join(variants_dir, dataset)\n",
    "    if dataset == \"gnomAD\":\n",
    "        vcfdir = os.path.join(vcfdir, \"genotype\")\n",
    "    for target in targets:\n",
    "        target_region = os.path.join(regions_dir, f\"{target}.bed\")\n",
    "        pams_ = pams if target.endswith(\"_CPF1\") else pams[:1]\n",
    "        results_target = os.path.join(results_dir, target)\n",
    "        for pam in pams_:\n",
    "            guidelen = 20 if pam == \"NGG\" else 23\n",
    "            crisprhawk_cmd = (\n",
    "                \"crisprhawk search \" \n",
    "                f\"-f {genome_dir} \" \n",
    "                f\"-r {target_region} \"\n",
    "                f\"-v {vcfdir} \"\n",
    "                f\"-p {pam} \"\n",
    "                f\"-g {guidelen} \"\n",
    "                f\"--haplotype-table \"\n",
    "                \"--threads 16 \"\n",
    "                f\"-o {results_target}\"\n",
    "                \"--verbosity 0\"\n",
    "            )\n",
    "            print(f\"Running search on {dataset} for target {target}\")\n",
    "            subprocess.call(crisprhawk_cmd, shell=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "data-analysis-ngs",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
